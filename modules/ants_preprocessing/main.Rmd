---
title: "Imaging Preprocessing (ANTsPy)"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include = FALSE}
# This code block sets up the engine environment
# Please do not remove me
raveio::pipeline_setup_rmd("ants_preprocessing")
options("raveio.debug" = TRUE)
```

Load necessary data in RAVE. At this stage, you are using R

Collect paths, make sure `image_path` exists. Can also use `Python` to do it.

```{rave collect_paths, export = "image_path_normalized", cue = "always", use_rave = TRUE}
image_path_normalized <- normalizePath(image_path, mustWork = TRUE)
```

Here comes the Python part

You can use all pipeline input variables in `Python` directly. RAVE converts them for you automatically. If you want Python to get access to more variables, use `rave` code blocks (see regular RAVE pipelines)

For easy debug, I manually copy everything from R to Python. Notice I use `python` block with no `use_rave` specified. This block will not be incorporated into the pipeline (debug inputs only)

```{r}
# Debug: Override `debug` when compiled as report
debug <- TRUE
```

```{python}
image_path_normalized = r.image_path_normalized
resample = r.resample
calculate_cortical_thickness = r.calculate_cortical_thickness
debug = r.debug
```

## Step 1: Load and resample the T1-weighted MRI

```{python load_original_image, export = "image_original", deps = c("image_path_normalized", "debug"), cue = "always", use_rave = TRUE}
image_original = ants.image_read(image_path_normalized)
if debug:
  image_original.plot(black_bg=False, nslices=12, ncol=4)
```

```{python resample_image, export = "image_resampled", deps = c("resample", "image_original"), use_rave = TRUE}
image_resampled = image_original
if resample == True:
  image_resampled = ants.resample_image(
    image = image_original, 
    resample_params = (256,256,256), 
    use_voxels = True, 
    interp_type = 4
  )
  if debug:
    image_resampled.plot(black_bg=False, nslices=12, ncol=4)
```

## Step 2: Align the native MRI to template

```{python register_to_template, export = "transforms", deps = "image_resampled", use_rave = TRUE}
transforms = antspynet.preprocess_brain_image(
  image_resampled,
  truncate_intensity = (0.01, 0.99),
  brain_extraction_modality = "t1",
  template = "croppedMni152",
  template_transform_type = "antsRegistrationSyNRepro[a]",
  do_bias_correction = True,
  do_denoising = True
)
skull_strip_template = transforms['preprocessed_image'].clone()
skull_strip_template[transforms['brain_mask'] == 0] = 0
transforms["skull_strip"] = skull_strip_template
```

Morph the normalized brain back to native brain

```{python normalize_brain, export = "normalized", deps = c("image_resampled", "transforms", "debug"), use_rave = TRUE}
normalized = ants.apply_transforms(
  fixed = image_resampled,
  moving = transforms['preprocessed_image'],
  transformlist = transforms['template_transforms']['invtransforms'],
  whichtoinvert = [True], interpolator="linear", verbose = True)
if debug:
  normalized.plot(black_bg=False, nslices=12, ncol=4)
```

Get brain-mask (skull-strip) on native brain

```{python generate_brain_mask, export = "brain_mask", deps = c("image_resampled", "transforms", "debug"), use_rave = TRUE}
brain_mask = ants.apply_transforms(
  fixed = image_resampled,
  moving = transforms['brain_mask'],
  transformlist=transforms['template_transforms']['invtransforms'],
  whichtoinvert = [True], interpolator="linear", verbose = True)
if debug:
  brain_mask.plot(black_bg=False, nslices=12, ncol=4)
```

Apply the brain-mask

```{python strip_skull, export = "skull_strip", deps = c("normalized", "brain_mask", "debug"), use_rave = TRUE}
skull_strip = normalized.clone()
skull_strip[brain_mask == 0] = 0
if debug:
  skull_strip.plot(black_bg=False, nslices=12, ncol=4)
```

## Step 4: Image segmentation

### Deep-Atropos (on template space)

```{python segmentation_using_Atropos, export = "atropos_template", deps = c("transforms"), use_rave = TRUE}
atropos_template = antspynet.deep_atropos(
  t1 = transforms["skull_strip"],
  do_preprocessing = False, 
  use_spatial_priors = True, 
  verbose = True)
```

Morph Atropos segmentation back onto the native space

```{python obtain_Atropos_on_native_brain, export = "atropos_native", deps = c("image_resampled", "atropos_template", "transforms"), use_rave = TRUE}
transform_list = transforms['template_transforms']['invtransforms']
atropos_native = {}
atropos_native['segmentation_image'] = ants.apply_transforms(
  fixed = image_resampled,
  moving = atropos_template['segmentation_image'],
  transformlist = transform_list,
  whichtoinvert = [True], interpolator="nearestNeighbor", verbose = False)

probability_images = []
atropos_native['probability_images'] = probability_images
for img in atropos_template['probability_images']:
  probability_images.append(ants.apply_transforms(
    fixed = image_resampled,
    moving = img,
    transformlist = transform_list,
    whichtoinvert = [True], interpolator="linear", verbose = False
  ))
```

-   Atropos segmentation: `atropos_native['segmentation_image']`
-   Atropos probabilities:
    -   CSF: `atropos_native['probability_images'][1]`
    -   Gray-matter: `atropos_native['probability_images'][2]`
    -   White-matter: `atropos_native['probability_images'][3]`
    -   Deep gray-matter: `atropos_native['probability_images'][4]`
    -   Brain-stem: `atropos_native['probability_images'][5]`
    -   Cerebellum: `atropos_native['probability_images'][6]`

### Desikan-Killiang-Tourville segmentation

```{python segmentation_using_Desikan-Killiang-Tourville_labeling, export = "DKTatlas_template", deps = c("transforms"), use_rave = TRUE}
DKTatlas_template = antspynet.desikan_killiany_tourville_labeling(
  t1 = transforms['skull_strip'],
  do_preprocessing = False, 
  return_probability_images = False,
  do_lobar_parcellation = False, 
  verbose = True 
)
```

Morph Desikan-Killiang-Tourville segmentation back to native space

```{python obtain_DKT_on_native_brain, export = "DKTatlas_native", deps = c("transforms", "DKTatlas_template", "image_resampled", "debug"), use_rave = TRUE}
DKTatlas_native = ants.apply_transforms(
  fixed = image_resampled,
  moving = DKTatlas_template,
  transformlist=transforms['template_transforms']['invtransforms'],
  whichtoinvert = [True], interpolator="nearestNeighbor", verbose = True)
if debug:
  DKTatlas_native.plot(cmap = "Set2", nslices=12, ncol=4)
```

## Step 5: Calculate cortical thickness

```{python cortical_thickness_using_Kelly_Kapowski, export = "cortical_thickness", deps = c("atropos_native", "calculate_cortical_thickness"), use_rave = TRUE}
cortical_thickness = None

if calculate_cortical_thickness:
  # https://www.medrxiv.org/content/10.1101/2020.10.19.20215392v1.full
  kk_segmentation = ants.image_clone(atropos_native['segmentation_image'])
  kk_segmentation[kk_segmentation == 4] = 3
  gray_matter = atropos_native['probability_images'][2]
  white_matter = (
    atropos_native['probability_images'][3] + 
    atropos_native['probability_images'][4]
  )
  cortical_thickness = ants.kelly_kapowski(
    s=kk_segmentation, g=gray_matter, w=white_matter,
    its=45, r=0.025, m=1.5, x=0, verbose=1)
```

```{python DKT_propagate_through_cortex, export = "DKT_propagated", deps = c("DKTatlas_native", "cortical_thickness", "calculate_cortical_thickness"), use_rave = TRUE}
DKT_propagated = None

if calculate_cortical_thickness:
  dtk_cortical_mask = ants.threshold_image(
    image=DKTatlas_native, low_thresh=1000, 
    high_thresh=3000, inval=1, outval=0)
  
  dtk = dtk_cortical_mask * DKTatlas_native
  
  kk_mask = ants.threshold_image(
    image=cortical_thickness, low_thresh=0,
    high_thresh = 0, inval = 0, outval = 1)
  
  DKT_propagated = ants.iMath(kk_mask, "PropagateLabelsThroughMask", kk_mask * dtk)
```

```{python get_average_regional_thickness_values, export = "cortical_thickness_regional_stats", deps = c("calculate_cortical_thickness", "DKT_propagated", "cortical_thickness"), use_rave = TRUE}
cortical_thickness_regional_stats = None

if calculate_cortical_thickness:
  cortical_thickness_regional_stats = ants.label_stats(
    cortical_thickness, DKT_propagated)
```

## Build, Visualize, & Run

Please make sure the following code block is at the end of your pipeline file. This block will build the pipeline and generate a `make-ants_preprocessing.R` script with your pipeline markdown file. `RAVE` will use the generated pipeline script to execute the pipeline in the dashboard application, or in massive production mode.

```{r build, echo=FALSE}
build_pipeline(make_file = "make-ants_preprocessing.R")
```

Once the pipeline script `make-ants_preprocessing.R` is built, you can visualize and execute the pipeline without the need of re-knit this document. Notice we use `r` block instead of `rave`. (This is because the code blocks are not part of pipeline targets.)

```{r visualize, echo=FALSE}
# Fixed usage, show pipeline graph
try({
  asNamespace("raveio")$pipeline_dependency_graph(
    pipeline_path = ".", glimpse = TRUE)
}, silent = TRUE)
```
